{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRESOURCES\\nhttps://python.langchain.com/v0.1/docs/use_cases/question_answering/quickstart/\\nhttps://python.langchain.com/docs/tutorials/rag/\\nhttps://scalexi.medium.com/implementing-a-retrieval-augmented-generation-rag-system-with-openais-api-using-langchain-ab39b60b4d9f\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "RESOURCES\n",
    "https://python.langchain.com/v0.1/docs/use_cases/question_answering/quickstart/\n",
    "https://python.langchain.com/docs/tutorials/rag/\n",
    "https://scalexi.medium.com/implementing-a-retrieval-augmented-generation-rag-system-with-openais-api-using-langchain-ab39b60b4d9f\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate and save [Langchain API key](https://docs.smith.langchain.com/how_to_guides/setup/create_account_api_key) to `.env`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup the API keys\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To provide context-rich data to the interior designer, I created a text repository comprising of fake expert data.\n",
    "I used ChatGPT to create the fake data.\n",
    "For easy handling, separate text files were created for different areas of the house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for reading text files containing information for RAG\n",
    "def read_txt_files_in_folder(folder_path):\n",
    "    all_texts = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                    filtered_content = ''.join([char for char in content if char not in ['**','#','##','###']])\n",
    "                    all_texts.append(filtered_content)\n",
    "    \n",
    "    return all_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the text files\n",
    "text = read_txt_files_in_folder('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5676\n"
     ]
    }
   ],
   "source": [
    "print(len(text))\n",
    "print(len(text[0])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text data should be split into manageable chunks that fit within the context window of the model.\n",
    "`RecursiveCharacterTextSplitter` recursively splits the text data into fragments using characters from the default list `[\"\\n\\n\", \"\\n\", \" \", \"\"]`, by finding the one that works. Chunks are created so that they are less than or equal in length to `chunk_size`.\n",
    "While there are several other text splitters, [this splitter](https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/recursive_text_splitter/) works best for generic text. \n",
    "\n",
    "`create_documents` is a little confusing since we have already processed the text documents into an array of strings. This method takes the array of string data as input and returns a set of 'document' objects that contain the split chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=200, \n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "## Converting text data into documents\n",
    "docs = text_splitter.create_documents(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "page_content='**Pro Tip:**\n",
      "Layer different shades of the same color for a sophisticated, monochromatic look. Add texture with natural fabrics like linen and wool.\n",
      "\n",
      " 2. **Layered Textiles for Cozy Comfort**\n",
      "\n",
      "Bedrooms in 2024 are embracing the concept of **“cocooning” with layered textiles.** From plush rugs to oversized throws, layering different fabrics adds warmth and comfort. Mixing materials like velvet, cotton, and faux fur creates a tactile experience that invites you to sink in and unwind.\n",
      "\n",
      " **Pro Tip:**\n",
      "Opt for a combination of heavy and light fabrics to create a balanced, luxurious feel. A faux fur throw paired with linen sheets can be both stylish and functional.\n",
      "\n",
      " 3. **Minimalist Luxury with Clean Lines**\n",
      "\n",
      "While comfort is key, **2024’s bedrooms also focus on minimalist luxury.** Clean lines, uncluttered spaces, and high-quality materials define this trend. Think of it as “less is more” but with a touch of opulence. The idea is to create a space that feels both serene and sophisticated.' metadata={'start_index': 693}\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))\n",
    "print(docs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have domain specific information, loaded from text files and processed into a format suitable for LangChain. For each user query, we should retrieve the appropriate snippets and provide them as context to the model. The RAG process is only as good as the retrieved snippets' relevance and quality. LangChain has [implementations](https://python.langchain.com/v0.2/docs/concepts/#retrieval) of multiple retrieval techniques that are suitable for different usecases.  \n",
    "\n",
    "Here, I use vector stores, one of the the simplest methods of retrieval. This is a beginner friendly method. Specifically, [Chroma](https://python.langchain.com/docs/integrations/vectorstores/chroma/) vector database was used to prepare the vector store. Here, unstructured text data is transformed into embeddings and during query phase, the query is converted to an embedding, the appropriate snippets are retrieved based on embedding similarity and an index corresponding to the relevant chunk is returned. Embeddings are computed using [OpenAI embedding models](https://python.langchain.com/docs/integrations/text_embedding/openai/).\n",
    "\n",
    "It is important to note that, in addition to the retrieval method, the size of the chunks and overlap used during text splitting play a key role on the effectiveness of RAG inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=docs, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of an LLM will be only as good as the prompt we give. [LangChain Hub](https://smith.langchain.com/hub) consists of pre-defined prompts for diverse usecases. created a prompt template based on `rag-prompt` from the Hub.   \n",
    "[PromptTemplate](https://python.langchain.com/v0.1/docs/modules/model_io/prompts/quick_start/) converts the string prompt to a LangChain prompt template. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Template based on hub.pull(\"rlm/rag-prompt\")\n",
    "template = \"\"\"Use the following pieces of context to answer the questions related to interior and exterior design of homes. Please respond without using double-quotation marks. \n",
    "If the question is not related to interior or exterior design, politely say that your are an assistant helping with interior and exterior design and tell the user to ask relavant questions, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] template=\"Use the following pieces of context to answer the questions related to interior and exterior design of homes. Please respond without using double-quotation marks. \\nIf the question is not related to interior or exterior design, politely say that your are an assistant helping with interior and exterior design and tell the user to ask relavant questions, don't try to make up an answer.\\nUse three sentences maximum and keep the answer as concise as possible.\\n{context}\\n\\nQuestion: {question}\\n\\nHelpful Answer:\"\n"
     ]
    }
   ],
   "source": [
    "print(custom_rag_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the LLM, I use OpenAI's `gpt-4o` model through `ChatOpenAI` API of LangChain. To try other OpenAI models, you can simply update the `model_name` argument with a different model. Check [OpenAI Plaform](https://platform.openai.com/docs/models) for all available models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.7, model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all the components required query our AI interior designer model. Now we create a chain that composes all the components and functions together. We use `RunnablePassthrough` to pass the user query into the prompt.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Consider using deep and bold colors like rich navy blues, forest greens, or charcoal grays to create depth and drama in your kitchen. Balance these hues with lighter countertops or backsplashes to maintain a harmonious look. Adding brass or gold fixtures can further enhance the luxurious feel.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"What color scheme should I use in a model kitchen?\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am an assistant focused on interior and exterior design. Please feel free to ask me any questions related to home design or decor.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Out of context question\n",
    "rag_chain.invoke(\"What is the capital of the United States?\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
